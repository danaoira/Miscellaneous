{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:41:04.087912",
     "start_time": "2016-11-09T14:38:34.681246"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download Audioscrobbler dataset\n",
    "! wget http://www.iro.umontreal.ca/~lisa/datasets/profiledata_06-May-2005.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:43:33.676040",
     "start_time": "2016-11-09T14:43:20.670119"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unzip Audioscrobbler dataset\n",
    "! tar xzvf profiledata_06-May-2005.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename Audioscrobbler data folder\n",
    "! mv profiledata_06-May-2005 data/audioscrobbler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete downloaded tarball\n",
    "! rm profiledata_06-May-2005.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:04:53.600415",
     "start_time": "2016-11-09T14:04:53.578682"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.ml.recommendation\n",
    "from pyspark.ml.recommendation import *\n",
    "import pyspark.ml.evaluation\n",
    "from pyspark.ml.evaluation import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:17:49.391028",
     "start_time": "2016-11-09T12:17:49.367460"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you started your notebook server with jupyspark.\n",
    "sc, spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:17:50.114263",
     "start_time": "2016-11-09T12:17:49.977820"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you don't have the tree command, you can install it with:\n",
    "#   Mac: brew install tree\n",
    "#   Ubuntu: sudo apt-get install tree!tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:12:47.826044",
     "start_time": "2016-11-09T14:12:47.747231"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mapping of users to artists\n",
    "# Space delimited fields: user_id, artist_id, play_count\n",
    "raw_user_artist_data = sc.textFile(\"data/audioscrobbler/user_artist_data.txt\")\n",
    "raw_user_artist_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:14:42.427313",
     "start_time": "2016-11-09T14:14:42.405677"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_user_artist_data(row):\n",
    "    \"\"\"Convert user_artist_data into [(user_id:int, artist_id:int, play_count:int, log_play_count:float)].\"\"\"\n",
    "    try:\n",
    "        user_id, artist_id, play_count = [int(x) for x in row.split(' ')]\n",
    "        log_play_count = float(np.log10(play_count))\n",
    "        return [(user_id, artist_id, play_count, log_play_count)]\n",
    "    except ValueError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:15:37.747954",
     "start_time": "2016-11-09T14:15:37.698829"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply schema to user_artist_data\n",
    "user_artist_data = raw_user_artist_data.flatMap(prep_user_artist_data)\n",
    "user_artist_schema = StructType([\n",
    "        StructField('user_id', IntegerType(), False),\n",
    "        StructField('artist_id', IntegerType(), False),\n",
    "        StructField('play_count', IntegerType(), False),\n",
    "        StructField('log_play_count', FloatType(), False)\n",
    "    ])\n",
    "user_artist_df = spark.createDataFrame(user_artist_data, user_artist_schema).persist()\n",
    "user_artist_df.registerTempTable('play_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:16:23.512036",
     "start_time": "2016-11-09T14:15:38.458761"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_artist_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:19:02.919707",
     "start_time": "2016-11-09T14:16:23.513783"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_artist_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:20:40.907301",
     "start_time": "2016-11-09T14:20:17.933458"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Play Count Stats:\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        min(play_count) AS min\n",
    "    ,   percentile_approx(play_count, 0.25) AS q_25\n",
    "    ,   percentile_approx(play_count, 0.5) AS median\n",
    "    ,   percentile_approx(play_count, 0.75) AS q_75\n",
    "    ,   max(play_count) AS max\n",
    "    FROM\n",
    "        play_counts\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.103859",
     "start_time": "2016-11-09T12:20:53.340301"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    1 - (\n",
    "        SELECT\n",
    "            Count(*) AS users_over_mean_play_count\n",
    "        FROM\n",
    "            play_counts\n",
    "        WHERE\n",
    "            play_count > 15\n",
    "    ) / (\n",
    "        SELECT\n",
    "            Count(*) AS total_users\n",
    "        FROM\n",
    "            play_counts\n",
    "    )\n",
    "    AS mean_percentile\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.205758",
     "start_time": "2016-11-09T12:20:54.105951"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_artist_data = sc.textFile(\"data/audioscrobbler/artist_data.txt\", use_unicode=False)\n",
    "raw_artist_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.233560",
     "start_time": "2016-11-09T12:20:54.207420"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_artist_data(row):\n",
    "    \"\"\"Convert raw_artist_data into [(artist_id:int, artist_name:str)].\"\"\"\n",
    "    try:\n",
    "        artist_id, artist_name = row.split('\\t')\n",
    "        artist_id = int(artist_id)\n",
    "        artist_name = artist_name.strip()\n",
    "        return [(int(artist_id), artist_name.strip())]\n",
    "    except ValueError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.263282",
     "start_time": "2016-11-09T12:20:54.234939"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_data = raw_artist_data.flatMap(prep_artist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.322025",
     "start_time": "2016-11-09T12:20:54.264851"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:20:54.388927",
     "start_time": "2016-11-09T12:20:54.323968"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_schema = StructType([\n",
    "    StructField('artist_id', IntegerType(), False),\n",
    "    StructField('artist_name', StringType(), False)\n",
    "    ])\n",
    "artist_df = spark.createDataFrame(artist_data, artist_schema).persist()\n",
    "artist_df.registerTempTable('artists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.411360",
     "start_time": "2016-11-09T12:20:54.390227"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "artist_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.506829",
     "start_time": "2016-11-09T12:21:04.412875"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_artist_alias_data = sc.textFile(\"data/audioscrobbler/artist_alias.txt\", use_unicode=False)\n",
    "raw_artist_alias_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.530564",
     "start_time": "2016-11-09T12:21:04.508244"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_artist_alias(row):\n",
    "    \"\"\"Convert a row from raw_artist_alias to [(alias_id:int, artist_id:int)]\"\"\"\n",
    "    try:\n",
    "        alias_id, artist_id = row.split('\\t')\n",
    "        return [(int(alias_id), int(artist_id))]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.554230",
     "start_time": "2016-11-09T12:21:04.532271"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_alias_data = raw_artist_alias_data.flatMap(prep_artist_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.578727",
     "start_time": "2016-11-09T12:21:04.557060"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_alias_schema = StructType([\n",
    "    StructField('alias_id', IntegerType(), False),\n",
    "    StructField('artist_id', IntegerType(), False)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:04.633968",
     "start_time": "2016-11-09T12:21:04.581100"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artist_alias_df = spark.createDataFrame(artist_alias_data, artist_alias_schema).persist()\n",
    "artist_alias_df.registerTempTable('artist_aliases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:05.893291",
     "start_time": "2016-11-09T12:21:04.635310"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "artist_alias_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:08.125990",
     "start_time": "2016-11-09T12:21:05.895064"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find artist aliases\n",
    "user_artist_corrections = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        play_counts.user_id\n",
    "    ,   play_counts.artist_id\n",
    "    ,   artist_aliases.artist_id AS corrected_artist_id\n",
    "    ,   play_counts.play_count\n",
    "    ,   play_counts.log_play_count\n",
    "    FROM\n",
    "        play_counts\n",
    "    INNER JOIN\n",
    "        artist_aliases\n",
    "    ON\n",
    "        play_counts.artist_id = artist_aliases.alias_id\n",
    "\"\"\")\n",
    "user_artist_corrections.show(), user_artist_corrections.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T12:21:09.266736",
     "start_time": "2016-11-09T12:21:08.127430"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What if it's a left join instead of an inner join?\n",
    "user_artist_corrections = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        play_counts.user_id\n",
    "    ,   play_counts.artist_id\n",
    "    ,   artist_aliases.artist_id AS corrected_artist_id\n",
    "    ,   play_counts.play_count\n",
    "    FROM\n",
    "        play_counts\n",
    "    LEFT JOIN\n",
    "        artist_aliases\n",
    "    ON\n",
    "        play_counts.artist_id = artist_aliases.alias_id\n",
    "\"\"\")\n",
    "user_artist_corrections.show(), user_artist_corrections.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:28:40.442135",
     "start_time": "2016-11-09T14:28:40.285272"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup artist aliases\n",
    "dealiased_play_counts_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        play_counts.user_id\n",
    "    ,   (CASE\n",
    "            WHEN artist_aliases.artist_id IS Null THEN play_counts.artist_id\n",
    "            ELSE artist_aliases.artist_id\n",
    "        END) as artist_id\n",
    "    ,   play_counts.play_count\n",
    "    ,   play_counts.log_play_count\n",
    "    FROM\n",
    "        play_counts\n",
    "    LEFT JOIN\n",
    "        artist_aliases\n",
    "    ON\n",
    "        play_counts.artist_id = artist_aliases.alias_id\n",
    "\"\"\")\n",
    "dealiased_play_counts_df.registerTempTable(\"dealiased_play_counts\")\n",
    "dealiased_play_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:28:58.625265",
     "start_time": "2016-11-09T14:28:45.652546"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        user_id\n",
    "    ,   artist_id\n",
    "    ,   Count(*) AS cnt\n",
    "    FROM\n",
    "        dealiased_play_counts\n",
    "    GROUP BY\n",
    "        user_id, artist_id\n",
    "    ORDER BY\n",
    "        Count(*) DESC\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:30:23.271730",
     "start_time": "2016-11-09T14:30:13.144994"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        artist_aliases.alias_id,\n",
    "        artists.artist_name\n",
    "    FROM\n",
    "        artist_aliases\n",
    "    JOIN\n",
    "        artists\n",
    "    ON\n",
    "        artist_aliases.alias_id = artists.artist_id\n",
    "    WHERE\n",
    "        artist_aliases.artist_id = 1018110\n",
    "    \"\"\").take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:30:35.033112",
     "start_time": "2016-11-09T14:30:23.273216"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_play_counts_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        user_id\n",
    "    ,   artist_id\n",
    "    ,   SUM(play_count) AS play_count\n",
    "    ,   LOG(10, SUM(play_count)) AS log_play_count\n",
    "    FROM\n",
    "        dealiased_play_counts\n",
    "    GROUP BY\n",
    "        user_id\n",
    "    ,   artist_id\n",
    "\"\"\")\n",
    "clean_play_counts_df.registerTempTable(\"clean_play_counts\")\n",
    "clean_play_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:30:35.072541",
     "start_time": "2016-11-09T14:30:35.034754"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "train, test = clean_play_counts_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:31:53.471694",
     "start_time": "2016-11-09T14:30:35.074139"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=5, seed=0, regParam=0.1, implicitPrefs=True, alpha=40,\n",
    "          userCol=\"user_id\", itemCol=\"artist_id\", ratingCol=\"log_play_count\", nonnegative=True)\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:31:54.291787",
     "start_time": "2016-11-09T14:31:53.473722"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:31:54.316579",
     "start_time": "2016-11-09T14:31:54.293278"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.registerTempTable(\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:32:30.763705",
     "start_time": "2016-11-09T14:31:54.318033"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:32:35.731084",
     "start_time": "2016-11-09T14:32:30.765317"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM predictions WHERE NOT ISNAN(prediction) ORDER BY prediction DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-09T14:32:36.254807",
     "start_time": "2016-11-09T14:32:35.732692"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM predictions WHERE NOT ISNAN(prediction) ORDER BY prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
